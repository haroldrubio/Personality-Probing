{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform The Raw Data from Alheimsins/b5-johnson-120-ipip-neo-pi-r\n",
    "Some of the questions may need some re-wording in order to activate the proper neurons in the models (hypothesis).\n",
    "Add \"I\" at the beginning, remove extra information and also append a \"choices\" string.\n",
    "\n",
    "We can perform 4 experiments to see if it makes a difference:\n",
    "1) Questions begin with \"I\" - choices worded as \"accurate\"\n",
    "1) Questions begin with \"I\" - choices worded as \"agree\"\n",
    "1) Questions don't begin with \"I\" - choices worded as \"accurate\"\n",
    "1) Questions don't begin with \"I\" - choices worded as \"agree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, sys\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_question(question: dict, prompt: str, prefix_i: bool = False) -> dict:\n",
    "    \"\"\"\n",
    "    Pre-processes a single question into the desired format as specified in the optional arguments\n",
    "    Args:\n",
    "        question (dict): A single question from the JS script\n",
    "        prefix_i (bool, optional): Pre-pends \"I\" to the beginning of the question and makes the original first word lowercase\n",
    "        choices (str, optional): Choose between using the word \"accurate\" and \"agree\" for the choices string\n",
    "        prompt(str, optional): The string on how to prompt the model to respond\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove question ID\n",
    "    del question['id']\n",
    "\n",
    "    # Check prefix boolean\n",
    "    if prefix_i:\n",
    "        question['text'] = question['text'][0].lower() + question['text'][1:]\n",
    "        question['text'] = 'I ' + question['text'] + '\\n'\n",
    "\n",
    "    # Add choices - deprecated - no longer asking multiple choice question\n",
    "    # Reason: models not trained specifically on multiple choice - easier to few-shot generation than multiple choice\n",
    "    '''\n",
    "    if choices == 'accurate':\n",
    "        choice_string = '1) Very Inaccurate\\n' + \\\n",
    "                        '2) Moderately Inaccurate\\n' + \\\n",
    "                        '3) Neutral\\n' + \\\n",
    "                        '4) Moderately Accurate\\n' + \\\n",
    "                        '5) Very Accurate\\n'\n",
    "    elif choices == 'agree':\n",
    "        choice_string = '1) Strongly Agree\\n' + \\\n",
    "                        '2) Agree\\n' + \\\n",
    "                        '3) Neutral\\n' + \\\n",
    "                        '4) Disagree\\n' + \\\n",
    "                        '5) Strongly Disagree\\n'\n",
    "    question['choice_string'] = choice_string\n",
    "    '''\n",
    "    # Construct a prefix string for open generation\n",
    "    generation_prefix = f\"{prompt}: You are happy.\\n\" + \\\n",
    "                        \"I feel happy.\\n\\n\" + \\\n",
    "                        f\"{prompt}: You are sad.\\n\" + \\\n",
    "                        \"I am sad.\\n\\n\" + \\\n",
    "                        f\"{prompt}: {question['text']}\\n\" + \\\n",
    "                        \"I\"\n",
    "\n",
    "    # Translate keyed to reverse_score\n",
    "    # This is because a minus key indicates that the question should correlate negatively with the trait/facet\n",
    "    question['reverse_score'] = question['facet'] == 'plus'\n",
    "\n",
    "    # Construct total string\n",
    "    question['question'] = generation_prefix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields in each question: dict_keys(['text', 'keyed', 'domain', 'facet', 'reverse_score', 'question'])\n",
      "A few examples\n",
      "Write out your thoughts on this statement: You are happy.\n",
      "I feel happy.\n",
      "\n",
      "Write out your thoughts on this statement: You are sad.\n",
      "I am sad.\n",
      "\n",
      "Write out your thoughts on this statement: I worry about things\n",
      "\n",
      "I\n",
      "\n",
      "Write out your thoughts on this statement: You are happy.\n",
      "I feel happy.\n",
      "\n",
      "Write out your thoughts on this statement: You are sad.\n",
      "I am sad.\n",
      "\n",
      "Write out your thoughts on this statement: I make friends easily\n",
      "\n",
      "I\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'Write out your thoughts on this statement'\n",
    "\n",
    "with open('./data/raw_questions.json', 'r') as f:\n",
    "    questions = json.load(f)\n",
    "for question in questions:\n",
    "    preprocess_question(question, prompt, prefix_i=True)\n",
    "\n",
    "print(f\"Fields in each question: {questions[0].keys()}\")\n",
    "print('A few examples')\n",
    "for i in range(2):\n",
    "    print(questions[i]['question'] + '\\n')\n",
    "\n",
    "dump = {}\n",
    "dump['prompt'] = prompt\n",
    "dump['questions'] = questions\n",
    "# Dump to file\n",
    "with open('./data/questions.json', 'w') as f:\n",
    "    json.dump(dump, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d1be0de97a20210aae8b935cc650f6c5ecaa0dda6f4a7d35b61bad57d138ea"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('psy': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
